---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me
I am a postdoc researcher at the University of Bergen in Bergen, Norway. Before coming to Norway I did a first postdoc at the CRIL lab in Lens, France for two years and a second postdoc at the National Institute of Advanced Industrial Science and Technology in Tokyo, Japan for 16 months. I completed my PhD in October 2021 after three years in the IRIT lab in Toulouse, France under the supervision of Andreas Herzig and Emiliano Lorini. Before that, I was a "normalienne" student of the Ecole Normale Supérieure de Lyon, and obtained my master's degree with the LMFI (Logique Mathématique et Fondements de l'Informatique, Mathematical Logic and Foundations of Computer Science) program at Paris Diderot University (now University of Paris).

## Research interests

I am interested in logical representations of theory of mind, and in particular knowledge, belief, and their dynamics. Within this, I work on elaborating lightweight frameworks in an attempt to bridge the gap between computationally complex philosophical and cognitive representations on the one hand, and practical application perspectives on the other hand, with a focus on epistemic planning. I am also interested in the dynamic interplay between trust and belief in the context of belief revision.

<!---
...
--->

**Keywords**

* Epistemic logic
* Epistemic planning
* Modal logics
* Belief revision
* Belief representation


## CV

See my CV in [French](https://eperrotin.github.io/files/CVfr.pdf) or [English](https://eperrotin.github.io/files/CVen.pdf).

<!---
## My papers, grouped by theme

**EL-O**

On the lightweight epistemic logic EL-O, see [the original _Artificial Intelligence_ paper](https://hal.science/hal-03147798v1/file/aij19_round3_v11.pdf) laying the basics of the logic and of epistemic planning with EL-O, stating in particular that EL-O planning can be polynomially translated into classical planning. For further developments, see [this KR 2020 paper](https://hal.science/hal-03015803/document) on parallel planning in EL-O, [this KR 2021](https://ut3-toulouseinp.hal.science/hal-03450078/document) paper for an extension to "knowing what", and [this paper](https://link.springer.com/chapter/10.1007/978-3-031-56595-3_11) on integrating the induction principle in EL-O.
Coming soon in AAAI 2025: _A Logical Analysis of Hanabi_, in which I extend EL-O common knowledge to any groups of agents, use that to give a complete formalization of the evolution of knowledge in the card game Hanabi, and finally give a small, finite fragment of that logic that is enough to fully capture the game.

**Other lightweight modal logics**

In [this IJCAI 2022 paper](https://hal.science/hal-03873341/document) and [this follow-up paper](https://link.springer.com/chapter/10.1007/978-3-031-44490-6_14) we propose a lightweight stit logic. In [this preliminary paper](https://hal.science/hal-03011708/document) and [this AAAI 2024 paper](https://ojs.aaai.org/index.php/AAAI/article/view/28919) we propose a lightweight epistemic-doxastic logic based on the non-standard operators of "true belief about" and "mere belief about".

**LDA**

The Logic of Doxastic Attitudes is a framework developed by Emiliano Lorini as a hybrid between semantic and syntactic representations of knowledge and beliefs, based on the concept of belief bases as well as the notions of explicit and implicit beliefs. As for my work on this, see [this ECAI 2020 paper](https://hal.science/hal-03008589v1/file/1266_paper.pdf) on capturing distributed belief in the framework and [this KR 2022 paper](https://hal.science/hal-03873252v1/file/kr2022-0024-lorini-et-al.pdf) on situating the private belief base updates of LDA w.r.t. standard DEL actions. Coming soon in AAAI 2025: _A Computationally Grounded Framework for Cognitive Attitudes_, in which we show how to capture notions such as attraction, repulsion and motivation in the framework; see the extended version [here](https://arxiv.org/pdf/2412.14073?).

**Belief Revision**

For my work in CRIL, see [this JELIA 2023 paper](https://hal.science/hal-04494547/document) and [the follow-up PRIMA 2024 paper](https://link.springer.com/chapter/10.1007/978-3-031-77367-9_14) on belief reconfiguration, where we study how to evaluate reliability of sources of information and how to take that reliability into account in interated belief revision. For earlier works, [this LORI 2019 paper](https://link.springer.com/chapter/10.1007/978-3-662-60292-8_15) and [this paper published in the Logic Journal of the IGPL](https://www.researchgate.net/profile/Fernando-Velazquez-Quesada/publication/353333636_A_semantic_approach_to_non-prioritized_belief_revision/links/60f565affb568a7098bda914/A-semantic-approach-to-non-prioritized-belief-revision.pdf) explore different aspects of the interplay between trust and belief revision. Finally, in this [PRICAI 2024 paper](https://link.springer.com/chapter/10.1007/978-981-96-0128-8_23) we propose a formal definition of what it means for one belief revision operator to be more change-reluctant than another.

**Miscellaneous**

In [this AiML 2020 paper](http://www.aiml.net/volumes/volume13/Herzig-Perrotin.pdf) we propose an alternative axiomatization of common knowledge, which arguably improves in intuitive clarity over previously existing proposals and can be summed up as: "if it is common knowledge that everybody knows whether φ then it is common knowledge whether φ".
--->
